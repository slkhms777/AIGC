## Introduce to Artificial Intelligence Homework



### Abstract

With the popularity of AI recently, more and more AI/CV researchers have attached a great importance to generative model-based image generation/systhesis technologies (In the following text, it will be uniformly abbreviated as "text to image", i.e., T2l). This article will focus on natural language-driven image generation/systhesis models and roughly summarize the previous related work and latest advances in this field.

### Introduction

Nowadays, the technologies of image generation/systhesis are a crucial research direction in computer vision field. With the surge of artificial intelligence generated content and especially deep learning-driven generation models' boosting, the technologies of image generation/systhesis have reached an unprecedented level. These technologise can not only create original static images but also videos and 3D content. Then I will introduce the history of generation models including previous work (AE and its variants, including DAE, VAE, VQ-VAE as well as diffusion model series) and latest advances (OpenAI DALLÂ·E series and Google Imagen series).



### Previous related work

* **GAN**

  * This work was proposed by Ian Goodfellow et al. in 2014, with its core innovation being in the firstly introduction of the "adversarial learning" mechanism. (I have read Ian's book on deep learning, so he left a deep impression on me). The **GAN** model has two main parts: one is the *Generator* and the other is *Discriminator*. The objective of *Generator* is to learn the distribution of real data and generate fake data that are as realistic as possible(for example, image) while the objective of *Discriminator* is to determine whether the images are real data or fake data generated by *Generator*. The ultimate goal of the **GAN** model is to train these two parts so that the *Generator* has the ability to generate fake images that cannot be distinguished by *Discriminator*. 
  * Advantages
    * High-quality data generation
    * No explicit probability modeling required
  * Disadvantages
    * Training instablity
    * High data requirement
    * Lack of image diversity

* **AE series**

  Due to the information density of images is low , there is a significant pixel redundancy. For example, the concept of "a cat" can be expressed in natural language with just a few words, whereas representing it as an RGB image requires hundreds or thousands of pixels. And a work named **MAE** proposed by Kaiming He et al. in 2021 has proved that if an image is masked by 75% region, it  can still be roughly reconstructed by a transformer-based image model. This further demonstrates that images are a low-information density modality. 

  Under this prior condition, AE series' main algorithm is to generate a image from a latent vector, whose dimensionality is much lower than the oiriginal image. 

  

  * **AutoEncoder(AE)**

    The inputs for **AE** are the original images. Each image is firstly encoded into a latent vector by an enoder, and then decoded into a reconstructed image by a decoder. The loss function used is mean squared error (MSE) Loss. 

    

  * **Denoising AutoEncoder(DAE)**

    The main difference between an **AutoEncoder (AE)** and a **Denoising AutoEncoder (DAE)** is that, in DAE, noise is deliberately added to the input images during training, and the model is trained to reconstruct the original, noise-free images from these corrupted inputs. Hence the name, **DAE**.

    

  Though **AE** and **DAE** are good at reconstructing the original images, reconstruction is the only thing they can do. The latent vector, also called bottleneck, is not modeled as a probability distribution. Therefore, it cannot be randomly sampled to generate new images.

  

  * **Variational AutoEncoder(VAE)**

    To solve the disadvantages of **AE** and **DAE**, **Variational AutoEncoder** not only compresses the input image into a latent vector, but also requires that these latent vectors follow a probability distribution (usually a standard normal distribution), while retaining the well-designed encoder-decoder architecture of **AE** and **DAE**.

    It should be noted that the loss of a VAE contains not only MSE loss but also KL loss. Specifically, the KL loss is calculated as:

    ```python
    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())
    ```

  

  **VAE** has many advantages, such as being able to generate new data samples rather than just reconstructing the input, and providing a clear probabilistic interpretation. However, it also has some drawbacks: on the other hand, since **VAE** models the latent space using continuous probability distributions, it cannot effectively handle discrete data. At the same time, when dealing with more complex or large-scale data, the scalability of the model can be limited, and the quality of generated samples is sometimes inferior to that of other generative models.

  

  * **Vector Quantized Variational AutoEncoder(VQ-VAE)**

    **VQ-VAE** uses a codebook to discretize the latent space, instead of modeling it with a normal distribution as in a standard **VAE**. This approach allows the features produced by the encoder to be quantized into discrete representations. While this enables effective compression and discrete modeling, **VQ-VAE** alone cannot directly generate new images. To sample or generate new images, an additional prior network (such as PixelCNN or Transformer) is required to model the distribution over the discrete latent variables. Without such a prior, **VQ-VAE** can only be used for tasks like reconstruction or feature extraction, rather than true generative modeling.

    It should be noted that the loss function of a **VQ-VAE** consists of three parts: the reconstruction loss (MSELoss), the codebook loss, and the commitment loss.

    For its **Prior** model, the loss function is CrossEntropyLoss, since it is an autoregressive model.

    ```python
    vqvae_loss = recon_loss + vq_loss + beta * commit_loss
    ```

    ```python
    prior_loss = CE_loss
    ```

    

    









